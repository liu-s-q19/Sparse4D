{"env_info": "sys.platform: linux\nPython: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\nCUDA available: True\nGPU 0: NVIDIA A100 80GB PCIe\nCUDA_HOME: /usr/local/cuda-11.7\nNVCC: Cuda compilation tools, release 11.7, V11.7.64\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\nPyTorch: 1.13.0+cu117\nPyTorch compiling details: PyTorch built with:\n  - GCC 9.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.7\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.5\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.14.0+cu117\nOpenCV: 4.10.0\nMMCV: 1.7.1\nMMCV Compiler: GCC 9.4\nMMCV CUDA Compiler: 11.7\nMMDetection: 2.28.2+", "config": "plugin = True\nplugin_dir = 'projects/mmdet3d_plugin/'\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nwork_dir = './work_dirs/sparse4dv3_temporal_r50_1x8_bs6_256x704'\ntotal_batch_size = 48\nnum_gpus = 8\nbatch_size = 6\nnum_iters_per_epoch = 586\nnum_epochs = 100\ncheckpoint_epoch_interval = 20\ncheckpoint_config = dict(interval=11720)\nlog_config = dict(\n    interval=51,\n    hooks=[\n        dict(type='TextLoggerHook', by_epoch=False),\n        dict(type='TensorboardLoggerHook')\n    ])\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\nfp16 = dict(loss_scale=32.0)\ninput_shape = (704, 256)\ntracking_test = True\ntracking_threshold = 0.2\nclass_names = [\n    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n]\nnum_classes = 10\nembed_dims = 256\nnum_groups = 8\nnum_decoder = 6\nnum_single_frame_decoder = 1\nuse_deformable_func = True\nstrides = [4, 8, 16, 32]\nnum_levels = 4\nnum_depth_layers = 3\ndrop_out = 0.1\ntemporal = True\ndecouple_attn = True\nwith_quality_estimation = True\nmodel = dict(\n    type='Sparse4D',\n    use_grid_mask=True,\n    use_deformable_func=True,\n    img_backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        frozen_stages=-1,\n        norm_eval=False,\n        style='pytorch',\n        with_cp=True,\n        out_indices=(0, 1, 2, 3),\n        norm_cfg=dict(type='BN', requires_grad=True),\n        pretrained='ckpt/resnet50-19c8e357.pth'),\n    img_neck=dict(\n        type='FPN',\n        num_outs=4,\n        start_level=0,\n        out_channels=256,\n        add_extra_convs='on_output',\n        relu_before_extra_convs=True,\n        in_channels=[256, 512, 1024, 2048]),\n    depth_branch=dict(\n        type='DenseDepthNet',\n        embed_dims=256,\n        num_depth_layers=3,\n        loss_weight=0.2),\n    head=dict(\n        type='Sparse4DHead',\n        cls_threshold_to_reg=0.05,\n        decouple_attn=True,\n        instance_bank=dict(\n            type='InstanceBank',\n            num_anchor=900,\n            embed_dims=256,\n            anchor='nuscenes_kmeans900.npy',\n            anchor_handler=dict(type='SparseBox3DKeyPointsGenerator'),\n            num_temp_instances=600,\n            confidence_decay=0.6,\n            feat_grad=False),\n        anchor_encoder=dict(\n            type='SparseBox3DEncoder',\n            vel_dims=3,\n            embed_dims=[128, 32, 32, 64],\n            mode='cat',\n            output_fc=False,\n            in_loops=1,\n            out_loops=4),\n        num_single_frame_decoder=1,\n        operation_order=[\n            'deformable', 'ffn', 'norm', 'refine', 'temp_gnn', 'gnn', 'norm',\n            'deformable', 'ffn', 'norm', 'refine', 'temp_gnn', 'gnn', 'norm',\n            'deformable', 'ffn', 'norm', 'refine', 'temp_gnn', 'gnn', 'norm',\n            'deformable', 'ffn', 'norm', 'refine', 'temp_gnn', 'gnn', 'norm',\n            'deformable', 'ffn', 'norm', 'refine', 'temp_gnn', 'gnn', 'norm',\n            'deformable', 'ffn', 'norm', 'refine'\n        ],\n        temp_graph_model=dict(\n            type='MultiheadAttention',\n            embed_dims=512,\n            num_heads=8,\n            batch_first=True,\n            dropout=0.1),\n        graph_model=dict(\n            type='MultiheadAttention',\n            embed_dims=512,\n            num_heads=8,\n            batch_first=True,\n            dropout=0.1),\n        norm_layer=dict(type='LN', normalized_shape=256),\n        ffn=dict(\n            type='AsymmetricFFN',\n            in_channels=512,\n            pre_norm=dict(type='LN'),\n            embed_dims=256,\n            feedforward_channels=1024,\n            num_fcs=2,\n            ffn_drop=0.1,\n            act_cfg=dict(type='ReLU', inplace=True)),\n        deformable_model=dict(\n            type='DeformableFeatureAggregation',\n            embed_dims=256,\n            num_groups=8,\n            num_levels=4,\n            num_cams=6,\n            attn_drop=0.15,\n            use_deformable_func=True,\n            use_camera_embed=True,\n            residual_mode='cat',\n            kps_generator=dict(\n                type='SparseBox3DKeyPointsGenerator',\n                num_learnable_pts=6,\n                fix_scale=[[0, 0, 0], [0.45, 0, 0], [-0.45, 0, 0],\n                           [0, 0.45, 0], [0, -0.45, 0], [0, 0, 0.45],\n                           [0, 0, -0.45]])),\n        refine_layer=dict(\n            type='SparseBox3DRefinementModule',\n            embed_dims=256,\n            num_cls=10,\n            refine_yaw=True,\n            with_quality_estimation=True),\n        sampler=dict(\n            type='SparseBox3DTarget',\n            num_dn_groups=5,\n            num_temp_dn_groups=3,\n            dn_noise_scale=[2.0, 2.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            max_dn_gt=32,\n            add_neg_dn=True,\n            cls_weight=2.0,\n            box_weight=0.25,\n            reg_weights=[2.0, 2.0, 2.0, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0],\n            cls_wise_reg_weights=dict(\n                {9: [2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]})),\n        loss_cls=dict(\n            type='FocalLoss',\n            use_sigmoid=True,\n            gamma=2.0,\n            alpha=0.25,\n            loss_weight=2.0),\n        loss_reg=dict(\n            type='SparseBox3DLoss',\n            loss_box=dict(type='L1Loss', loss_weight=0.25),\n            loss_centerness=dict(type='CrossEntropyLoss', use_sigmoid=True),\n            loss_yawness=dict(type='GaussianFocalLoss'),\n            cls_allow_reverse=[5]),\n        decoder=dict(type='SparseBox3DDecoder'),\n        reg_weights=[2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]))\ndataset_type = 'NuScenes3DDetTrackDataset'\ndata_root = 'data/nuscenes/'\nanno_root = 'data/nuscenes_anno_pkls/'\nfile_client_args = dict(backend='disk')\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(\n        type='LoadPointsFromFile',\n        coord_type='LIDAR',\n        load_dim=5,\n        use_dim=5,\n        file_client_args=dict(backend='disk')),\n    dict(type='ResizeCropFlipImage'),\n    dict(type='MultiScaleDepthMapGenerator', downsample=[4, 8, 16]),\n    dict(type='BBoxRotation'),\n    dict(type='PhotoMetricDistortionMultiViewImage'),\n    dict(\n        type='NormalizeMultiviewImage',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(\n        type='CircleObjectRangeFilter',\n        class_dist_thred=[55, 55, 55, 55, 55, 55, 55, 55, 55, 55]),\n    dict(\n        type='InstanceNameFilter',\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ]),\n    dict(type='NuScenesSparse4DAdaptor'),\n    dict(\n        type='Collect',\n        keys=[\n            'img', 'timestamp', 'projection_mat', 'image_wh', 'gt_depth',\n            'focal', 'gt_bboxes_3d', 'gt_labels_3d'\n        ],\n        meta_keys=['T_global', 'T_global_inv', 'timestamp', 'instance_id'])\n]\ntest_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='ResizeCropFlipImage'),\n    dict(\n        type='NormalizeMultiviewImage',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='NuScenesSparse4DAdaptor'),\n    dict(\n        type='Collect',\n        keys=['img', 'timestamp', 'projection_mat', 'image_wh'],\n        meta_keys=['T_global', 'T_global_inv', 'timestamp'])\n]\ninput_modality = dict(\n    use_lidar=False,\n    use_camera=True,\n    use_radar=False,\n    use_map=False,\n    use_external=False)\ndata_basic_config = dict(\n    type='NuScenes3DDetTrackDataset',\n    data_root='data/nuscenes/',\n    classes=[\n        'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',\n        'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n    ],\n    modality=dict(\n        use_lidar=False,\n        use_camera=True,\n        use_radar=False,\n        use_map=False,\n        use_external=False),\n    version='v1.0-trainval')\ndata_aug_conf = dict(\n    resize_lim=(0.4, 0.47),\n    final_dim=(256, 704),\n    bot_pct_lim=(0.0, 0.0),\n    rot_lim=(-5.4, 5.4),\n    H=900,\n    W=1600,\n    rand_flip=True,\n    rot3d_range=[-0.3925, 0.3925])\ndata = dict(\n    samples_per_gpu=6,\n    workers_per_gpu=6,\n    train=dict(\n        type='NuScenes3DDetTrackDataset',\n        data_root='data/nuscenes/',\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ],\n        modality=dict(\n            use_lidar=False,\n            use_camera=True,\n            use_radar=False,\n            use_map=False,\n            use_external=False),\n        version='v1.0-trainval',\n        ann_file='data/nuscenes_anno_pkls/nuscenes-mini_infos_train.pkl',\n        pipeline=[\n            dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n            dict(\n                type='LoadPointsFromFile',\n                coord_type='LIDAR',\n                load_dim=5,\n                use_dim=5,\n                file_client_args=dict(backend='disk')),\n            dict(type='ResizeCropFlipImage'),\n            dict(type='MultiScaleDepthMapGenerator', downsample=[4, 8, 16]),\n            dict(type='BBoxRotation'),\n            dict(type='PhotoMetricDistortionMultiViewImage'),\n            dict(\n                type='NormalizeMultiviewImage',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(\n                type='CircleObjectRangeFilter',\n                class_dist_thred=[55, 55, 55, 55, 55, 55, 55, 55, 55, 55]),\n            dict(\n                type='InstanceNameFilter',\n                classes=[\n                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',\n                    'traffic_cone'\n                ]),\n            dict(type='NuScenesSparse4DAdaptor'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'timestamp', 'projection_mat', 'image_wh',\n                    'gt_depth', 'focal', 'gt_bboxes_3d', 'gt_labels_3d'\n                ],\n                meta_keys=[\n                    'T_global', 'T_global_inv', 'timestamp', 'instance_id'\n                ])\n        ],\n        test_mode=False,\n        data_aug_conf=dict(\n            resize_lim=(0.4, 0.47),\n            final_dim=(256, 704),\n            bot_pct_lim=(0.0, 0.0),\n            rot_lim=(-5.4, 5.4),\n            H=900,\n            W=1600,\n            rand_flip=True,\n            rot3d_range=[-0.3925, 0.3925]),\n        with_seq_flag=True,\n        sequences_split_num=2,\n        keep_consistent_seq_aug=True),\n    val=dict(\n        type='NuScenes3DDetTrackDataset',\n        data_root='data/nuscenes/',\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ],\n        modality=dict(\n            use_lidar=False,\n            use_camera=True,\n            use_radar=False,\n            use_map=False,\n            use_external=False),\n        version='v1.0-trainval',\n        ann_file='data/nuscenes_anno_pkls/nuscenes-mini_infos_val.pkl',\n        pipeline=[\n            dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n            dict(type='ResizeCropFlipImage'),\n            dict(\n                type='NormalizeMultiviewImage',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='NuScenesSparse4DAdaptor'),\n            dict(\n                type='Collect',\n                keys=['img', 'timestamp', 'projection_mat', 'image_wh'],\n                meta_keys=['T_global', 'T_global_inv', 'timestamp'])\n        ],\n        data_aug_conf=dict(\n            resize_lim=(0.4, 0.47),\n            final_dim=(256, 704),\n            bot_pct_lim=(0.0, 0.0),\n            rot_lim=(-5.4, 5.4),\n            H=900,\n            W=1600,\n            rand_flip=True,\n            rot3d_range=[-0.3925, 0.3925]),\n        test_mode=True,\n        tracking=True,\n        tracking_threshold=0.2),\n    test=dict(\n        type='NuScenes3DDetTrackDataset',\n        data_root='data/nuscenes/',\n        classes=[\n            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'\n        ],\n        modality=dict(\n            use_lidar=False,\n            use_camera=True,\n            use_radar=False,\n            use_map=False,\n            use_external=False),\n        version='v1.0-trainval',\n        ann_file='data/nuscenes_anno_pkls/nuscenes-mini_infos_val.pkl',\n        pipeline=[\n            dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n            dict(type='ResizeCropFlipImage'),\n            dict(\n                type='NormalizeMultiviewImage',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='NuScenesSparse4DAdaptor'),\n            dict(\n                type='Collect',\n                keys=['img', 'timestamp', 'projection_mat', 'image_wh'],\n                meta_keys=['T_global', 'T_global_inv', 'timestamp'])\n        ],\n        data_aug_conf=dict(\n            resize_lim=(0.4, 0.47),\n            final_dim=(256, 704),\n            bot_pct_lim=(0.0, 0.0),\n            rot_lim=(-5.4, 5.4),\n            H=900,\n            W=1600,\n            rand_flip=True,\n            rot3d_range=[-0.3925, 0.3925]),\n        test_mode=True,\n        tracking=True,\n        tracking_threshold=0.2))\noptimizer = dict(\n    type='AdamW',\n    lr=0.0006,\n    weight_decay=0.001,\n    paramwise_cfg=dict(custom_keys=dict(img_backbone=dict(lr_mult=0.5))))\noptimizer_config = dict(grad_clip=dict(max_norm=25, norm_type=2))\nlr_config = dict(\n    policy='CosineAnnealing',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.3333333333333333,\n    min_lr_ratio=0.001)\nrunner = dict(type='IterBasedRunner', max_iters=58600)\nvis_pipeline = [\n    dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n    dict(type='Collect', keys=['img'], meta_keys=['timestamp', 'lidar2img'])\n]\nevaluation = dict(\n    interval=11720,\n    pipeline=[\n        dict(type='LoadMultiViewImageFromFiles', to_float32=True),\n        dict(\n            type='Collect', keys=['img'], meta_keys=['timestamp', 'lidar2img'])\n    ])\ngpu_ids = range(0, 1)\n", "seed": 0, "exp_name": "sparse4dv3_temporal_r50_1x8_bs6_256x704.py"}
{"mode": "train", "epoch": 1, "iter": 51, "lr": 0.00012, "memory": 14359, "data_time": 0.06342, "loss_cls_0": 1.22334, "loss_box_0": 2.55026, "loss_cns_0": 0.57005, "loss_yns_0": 0.16362, "loss_cls_1": 1.27045, "loss_box_1": 2.98679, "loss_cns_1": 0.50371, "loss_yns_1": 0.16782, "loss_cls_2": 1.29271, "loss_box_2": 3.10169, "loss_cns_2": 0.50067, "loss_yns_2": 0.17581, "loss_cls_3": 1.2707, "loss_box_3": 3.17899, "loss_cns_3": 0.51218, "loss_yns_3": 0.17183, "loss_cls_4": 1.24396, "loss_box_4": 3.28502, "loss_cns_4": 0.49689, "loss_yns_4": 0.17296, "loss_cls_5": 1.26494, "loss_box_5": 3.32659, "loss_cns_5": 0.4936, "loss_yns_5": 0.17693, "loss_cls_dn_0": 0.50507, "loss_box_dn_0": 1.06363, "loss_cls_dn_1": 0.4587, "loss_box_dn_1": 1.57494, "loss_cls_dn_2": 0.46486, "loss_box_dn_2": 1.62939, "loss_cls_dn_3": 0.45184, "loss_box_dn_3": 1.6844, "loss_cls_dn_4": 0.43876, "loss_box_dn_4": 1.75477, "loss_cls_dn_5": 0.45611, "loss_box_dn_5": 1.82641, "loss_dense_depth": 1.2909, "loss": 43.70129, "grad_norm": 98.0097, "time": 0.91816}
{"mode": "train", "epoch": 1, "iter": 102, "lr": 0.00014, "memory": 14359, "data_time": 0.02071, "loss_cls_0": 1.05023, "loss_box_0": 2.31214, "loss_cns_0": 0.60927, "loss_yns_0": 0.15922, "loss_cls_1": 1.10271, "loss_box_1": 2.87188, "loss_cns_1": 0.57727, "loss_yns_1": 0.16734, "loss_cls_2": 1.12305, "loss_box_2": 2.84208, "loss_cns_2": 0.58897, "loss_yns_2": 0.16435, "loss_cls_3": 1.12603, "loss_box_3": 2.8415, "loss_cns_3": 0.59602, "loss_yns_3": 0.1686, "loss_cls_4": 1.12578, "loss_box_4": 2.85034, "loss_cns_4": 0.59207, "loss_yns_4": 0.17232, "loss_cls_5": 1.12428, "loss_box_5": 2.87607, "loss_cns_5": 0.59144, "loss_yns_5": 0.17035, "loss_cls_dn_0": 0.39876, "loss_box_dn_0": 0.88998, "loss_cls_dn_1": 0.3065, "loss_box_dn_1": 1.04312, "loss_cls_dn_2": 0.34664, "loss_box_dn_2": 1.03763, "loss_cls_dn_3": 0.37113, "loss_box_dn_3": 1.05896, "loss_cls_dn_4": 0.36854, "loss_box_dn_4": 1.0793, "loss_cls_dn_5": 0.37127, "loss_box_dn_5": 1.11291, "loss_dense_depth": 1.07023, "loss": 37.25826, "grad_norm": 58.91773, "time": 0.81229}
{"mode": "train", "epoch": 1, "iter": 153, "lr": 0.00016, "memory": 14359, "data_time": 0.02018, "loss_cls_0": 0.97902, "loss_box_0": 2.25701, "loss_cns_0": 0.6094, "loss_yns_0": 0.16098, "loss_cls_1": 1.04551, "loss_box_1": 2.5823, "loss_cns_1": 0.61503, "loss_yns_1": 0.16239, "loss_cls_2": 1.05943, "loss_box_2": 2.54579, "loss_cns_2": 0.62587, "loss_yns_2": 0.16398, "loss_cls_3": 1.05981, "loss_box_3": 2.5307, "loss_cns_3": 0.62793, "loss_yns_3": 0.15874, "loss_cls_4": 1.06468, "loss_box_4": 2.53336, "loss_cns_4": 0.62687, "loss_yns_4": 0.15665, "loss_cls_5": 1.06771, "loss_box_5": 2.54333, "loss_cns_5": 0.62938, "loss_yns_5": 0.15738, "loss_cls_dn_0": 0.32563, "loss_box_dn_0": 0.83521, "loss_cls_dn_1": 0.21482, "loss_box_dn_1": 0.93296, "loss_cls_dn_2": 0.23044, "loss_box_dn_2": 0.92252, "loss_cls_dn_3": 0.25536, "loss_box_dn_3": 0.94124, "loss_cls_dn_4": 0.26553, "loss_box_dn_4": 0.9627, "loss_cls_dn_5": 0.28354, "loss_box_dn_5": 0.99095, "loss_dense_depth": 0.93671, "loss": 34.06086, "grad_norm": 54.05424, "time": 0.83874}
{"mode": "train", "epoch": 1, "iter": 204, "lr": 0.00018, "memory": 14359, "data_time": 0.02121, "loss_cls_0": 0.99217, "loss_box_0": 2.48816, "loss_cns_0": 0.60342, "loss_yns_0": 0.15175, "loss_cls_1": 1.05795, "loss_box_1": 2.74936, "loss_cns_1": 0.61495, "loss_yns_1": 0.15664, "loss_cls_2": 1.07656, "loss_box_2": 2.68968, "loss_cns_2": 0.62971, "loss_yns_2": 0.15139, "loss_cls_3": 1.07654, "loss_box_3": 2.68057, "loss_cns_3": 0.6317, "loss_yns_3": 0.1514, "loss_cls_4": 1.06769, "loss_box_4": 2.67729, "loss_cns_4": 0.62932, "loss_yns_4": 0.14988, "loss_cls_5": 1.08023, "loss_box_5": 2.68111, "loss_cns_5": 0.62958, "loss_yns_5": 0.14759, "loss_cls_dn_0": 0.25185, "loss_box_dn_0": 0.8203, "loss_cls_dn_1": 0.18964, "loss_box_dn_1": 0.89967, "loss_cls_dn_2": 0.19793, "loss_box_dn_2": 0.8889, "loss_cls_dn_3": 0.20535, "loss_box_dn_3": 0.91263, "loss_cls_dn_4": 0.20584, "loss_box_dn_4": 0.93395, "loss_cls_dn_5": 0.21795, "loss_box_dn_5": 0.96393, "loss_dense_depth": 0.90516, "loss": 34.55776, "grad_norm": 51.03499, "time": 0.8106}
{"mode": "train", "epoch": 1, "iter": 255, "lr": 0.0002, "memory": 14359, "data_time": 0.02194, "loss_cls_0": 0.92616, "loss_box_0": 2.13709, "loss_cns_0": 0.6107, "loss_yns_0": 0.1481, "loss_cls_1": 0.98229, "loss_box_1": 2.44396, "loss_cns_1": 0.61147, "loss_yns_1": 0.15251, "loss_cls_2": 1.0118, "loss_box_2": 2.37339, "loss_cns_2": 0.63132, "loss_yns_2": 0.15189, "loss_cls_3": 1.0294, "loss_box_3": 2.36891, "loss_cns_3": 0.63879, "loss_yns_3": 0.15024, "loss_cls_4": 1.00892, "loss_box_4": 2.38183, "loss_cns_4": 0.63039, "loss_yns_4": 0.15058, "loss_cls_5": 1.01091, "loss_box_5": 2.39123, "loss_cns_5": 0.63201, "loss_yns_5": 0.14918, "loss_cls_dn_0": 0.23804, "loss_box_dn_0": 0.8088, "loss_cls_dn_1": 0.17587, "loss_box_dn_1": 0.91092, "loss_cls_dn_2": 0.18311, "loss_box_dn_2": 0.88898, "loss_cls_dn_3": 0.19177, "loss_box_dn_3": 0.90025, "loss_cls_dn_4": 0.19196, "loss_box_dn_4": 0.91303, "loss_cls_dn_5": 0.1976, "loss_box_dn_5": 0.92942, "loss_dense_depth": 0.9227, "loss": 32.17553, "grad_norm": 55.53865, "time": 0.83873}
{"mode": "train", "epoch": 1, "iter": 306, "lr": 0.00022, "memory": 14359, "data_time": 0.02222, "loss_cls_0": 0.86223, "loss_box_0": 2.06637, "loss_cns_0": 0.61271, "loss_yns_0": 0.13964, "loss_cls_1": 0.91757, "loss_box_1": 2.20652, "loss_cns_1": 0.62382, "loss_yns_1": 0.14259, "loss_cls_2": 0.96763, "loss_box_2": 2.12472, "loss_cns_2": 0.64406, "loss_yns_2": 0.14172, "loss_cls_3": 0.95889, "loss_box_3": 2.1059, "loss_cns_3": 0.64569, "loss_yns_3": 0.13819, "loss_cls_4": 0.96478, "loss_box_4": 2.10235, "loss_cns_4": 0.64315, "loss_yns_4": 0.13653, "loss_cls_5": 0.96486, "loss_box_5": 2.10619, "loss_cns_5": 0.64341, "loss_yns_5": 0.13733, "loss_cls_dn_0": 0.21776, "loss_box_dn_0": 0.78584, "loss_cls_dn_1": 0.15081, "loss_box_dn_1": 0.79931, "loss_cls_dn_2": 0.15564, "loss_box_dn_2": 0.76389, "loss_cls_dn_3": 0.16239, "loss_box_dn_3": 0.7634, "loss_cls_dn_4": 0.16275, "loss_box_dn_4": 0.77156, "loss_cls_dn_5": 0.16785, "loss_box_dn_5": 0.7836, "loss_dense_depth": 0.84641, "loss": 29.52808, "grad_norm": 45.71379, "time": 0.82503}
{"mode": "train", "epoch": 1, "iter": 357, "lr": 0.00024, "memory": 14359, "data_time": 0.02163, "loss_cls_0": 0.89217, "loss_box_0": 2.06934, "loss_cns_0": 0.61147, "loss_yns_0": 0.13884, "loss_cls_1": 0.93845, "loss_box_1": 2.23047, "loss_cns_1": 0.62557, "loss_yns_1": 0.13836, "loss_cls_2": 0.96671, "loss_box_2": 2.1528, "loss_cns_2": 0.64422, "loss_yns_2": 0.13746, "loss_cls_3": 0.96788, "loss_box_3": 2.1334, "loss_cns_3": 0.64814, "loss_yns_3": 0.13685, "loss_cls_4": 0.96195, "loss_box_4": 2.13181, "loss_cns_4": 0.64284, "loss_yns_4": 0.135, "loss_cls_5": 0.96492, "loss_box_5": 2.12928, "loss_cns_5": 0.64111, "loss_yns_5": 0.13538, "loss_cls_dn_0": 0.22592, "loss_box_dn_0": 0.78453, "loss_cls_dn_1": 0.1408, "loss_box_dn_1": 0.7961, "loss_cls_dn_2": 0.14474, "loss_box_dn_2": 0.77351, "loss_cls_dn_3": 0.15118, "loss_box_dn_3": 0.78094, "loss_cls_dn_4": 0.15175, "loss_box_dn_4": 0.79323, "loss_cls_dn_5": 0.15499, "loss_box_dn_5": 0.80989, "loss_dense_depth": 0.86133, "loss": 29.74331, "grad_norm": 46.78686, "time": 0.82934}
{"mode": "train", "epoch": 1, "iter": 408, "lr": 0.00026, "memory": 14359, "data_time": 0.02123, "loss_cls_0": 0.85904, "loss_box_0": 2.10513, "loss_cns_0": 0.61326, "loss_yns_0": 0.13934, "loss_cls_1": 0.90995, "loss_box_1": 2.1933, "loss_cns_1": 0.63048, "loss_yns_1": 0.13669, "loss_cls_2": 0.94634, "loss_box_2": 2.11142, "loss_cns_2": 0.64377, "loss_yns_2": 0.13553, "loss_cls_3": 0.93602, "loss_box_3": 2.10828, "loss_cns_3": 0.64677, "loss_yns_3": 0.13532, "loss_cls_4": 0.92517, "loss_box_4": 2.1037, "loss_cns_4": 0.64052, "loss_yns_4": 0.13419, "loss_cls_5": 0.93742, "loss_box_5": 2.10941, "loss_cns_5": 0.6379, "loss_yns_5": 0.1365, "loss_cls_dn_0": 0.21768, "loss_box_dn_0": 0.77801, "loss_cls_dn_1": 0.13737, "loss_box_dn_1": 0.8383, "loss_cls_dn_2": 0.13835, "loss_box_dn_2": 0.8216, "loss_cls_dn_3": 0.14285, "loss_box_dn_3": 0.82912, "loss_cls_dn_4": 0.14534, "loss_box_dn_4": 0.84681, "loss_cls_dn_5": 0.15046, "loss_box_dn_5": 0.86771, "loss_dense_depth": 0.94, "loss": 29.72905, "grad_norm": 42.87789, "time": 0.81333}
